{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fe17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import to_one_hot\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier,NearestCentroid,RadiusNeighborsClassifier\n",
    "from sklearn.svm import SVC,NuSVC,LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier,PassiveAggressiveClassifier\n",
    "scorings=['accuracy',\n",
    "         'balanced_accuracy',\n",
    "         'average_precision',\n",
    "         'neg_brier_score',\n",
    "         'f1',\n",
    "         'f1_micro',\n",
    "         'f1_macro',\n",
    "         'f1_weighted',\n",
    "         'neg_log_loss',\n",
    "         'precision',\n",
    "         'recall',\n",
    "         'jaccard',\n",
    "         'roc_auc',\n",
    "         'roc_auc_ovr',\n",
    "         'roc_auc_ovo',\n",
    "         'roc_auc_ovr_weighted',\n",
    "         'roc_auc_ovo_weighted']\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    RidgeClassifier(),\n",
    "    SGDClassifier(max_iter=1000, tol=1e-3),\n",
    "    PassiveAggressiveClassifier(max_iter=1000, random_state=0,tol=1e-3),\n",
    "    NearestCentroid(),\n",
    "    RadiusNeighborsClassifier(radius=1.0),\n",
    "    VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard'),\n",
    "    BaggingClassifier(base_estimator=SVC(),n_estimators=10, random_state=0),\n",
    "    ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    NuSVC(),\n",
    "    LinearSVC(random_state=0, tol=1e-5),\n",
    "]\n",
    "names = [\n",
    "    \"Nearest Neighbors\", \n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\", \n",
    "    \"Random Forest\", \n",
    "    \"Neural Net\", \n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"Ridge\",\n",
    "    \"SGD\",\n",
    "    \"PassiveAggressive\",\n",
    "    \"NearestCentroid\",\n",
    "    \"Radius Neighbors\",\n",
    "    \"Voting\",\n",
    "    \"Bagging\",\n",
    "    \"ExtraTrees\",\n",
    "    \"GradientBoosting\",\n",
    "    \"Linear SVM\", \n",
    "    \"RBF SVM\",\n",
    "    \"Nu SVM\",\n",
    "    \"Linear SVM2\"\n",
    "]\n",
    "classifier=[]\n",
    "score_name=[]\n",
    "scoring=[]\n",
    "scoring_avg=[]\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QDA,Naive Bayes,AdaBoost,Neural Net\n",
    "per_player=pd.read_csv('per_player.csv')\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "plt.title('MSE individuals per player')\n",
    "plt.grid()\n",
    "ax.set_xticks(np.arange(0,1, 0.05))\n",
    "sns.histplot(data=per_player, x='MSE',bins=210)\n",
    "for i in range(len(classifiers)):\n",
    "    scores=cross_validate(classifiers[i], per_player.drop(columns=['good_bad','MSE','MSE_var']), per_player['good_bad'],scoring=scorings)\n",
    "    for score in scorings:\n",
    "        data.append(\"individuals per player\")\n",
    "        classifier.append(names[i])\n",
    "        score_name.append(score)\n",
    "        scoring.append(scores['test_'+str(score)])\n",
    "        scoring_avg.append(sum(scores['test_'+str(score)])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes,Random Forest,QDA\n",
    "per_game=pd.read_csv('per_game.csv')\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "plt.title('MSE individuals per game')\n",
    "plt.grid()\n",
    "ax.set_xticks(np.arange(0,1, 0.05))\n",
    "sns.histplot(data=per_game, x='MSE',bins=210)\n",
    "for i in range(len(classifiers)):\n",
    "    scores=cross_validate(classifiers[i],per_game.drop(columns=['good_bad','MSE','MSE_var']), per_game['good_bad'],scoring=scorings)\n",
    "    for score in scorings:\n",
    "        data.append(\"individuals per game\")\n",
    "        classifier.append(names[i])\n",
    "        score_name.append(score)\n",
    "        scoring.append(scores['test_'+str(score)])\n",
    "        scoring_avg.append(sum(scores['test_'+str(score)])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edff07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost,Random Forest,Decision Tree,Gaussian Process,\n",
    "real=pd.read_csv('real.csv')\n",
    "real=real[(real['GameID']<211)|((270<real['GameID'])&(real['GameID']<481))]\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "plt.title('aggregate')\n",
    "plt.grid()\n",
    "ax.set_xticks(np.arange(0,1, 0.01))\n",
    "sns.histplot(data=real, x='MSE',bins=210)\n",
    "for i in range(len(classifiers)):\n",
    "    scores=cross_validate(classifiers[i], real.drop(columns=['good_bad','MSE']), real['good_bad'],scoring=scorings)\n",
    "    for score in scorings:\n",
    "        data.append(\"aggregate\")\n",
    "        classifier.append(names[i])\n",
    "        score_name.append(score)\n",
    "        scoring.append(scores['test_'+str(score)])\n",
    "        scoring_avg.append(sum(scores['test_'+str(score)])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame.from_dict({'classifier':classifier,'score_name':score_name,'scoring':scoring,'scoring avg':scoring_avg,'data':data})\n",
    "results.to_csv('results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes,Neural Net,QDA,Random Forest\n",
    "df=pd.read_csv('per_game_and_player.csv')\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "plt.title('MSE individuals per game and player')\n",
    "plt.grid()\n",
    "ax.set_xticks(np.arange(0,1, 0.05))\n",
    "sns.histplot(data=df, x='MSE',bins=210)\n",
    "for i in range(len(classifiers)):\n",
    "    #if i!=1:\n",
    "    scores=cross_validate(classifiers[i], df.drop(columns=['B.1','B.1_baseline','B.2','B.2_baseline','B.3','B.3_baseline','B.4','B.4_baseline','B.5','B.5_baseline','good_bad','MSE']), df['good_bad'],scoring=scorings)\n",
    "    for score in scorings:\n",
    "        data.append(\"individuals per game and player\")\n",
    "        classifier.append(names[i])\n",
    "        score_name.append(score)\n",
    "        scoring.append(scores['test_'+str(score)])\n",
    "        scoring_avg.append(sum(scores['test_'+str(score)])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('test.csv')\n",
    "df=df[df['player_id_in_group']==2]\n",
    "def TR_average(participant_code,hotel_id,df):\n",
    "    return df[(df['participant_code']!=participant_code)&(df['hotel_id']==hotel_id)]['TR'].mean()\n",
    "\n",
    "def TR_majorty(TR_avg):\n",
    "    if TR_avg>0.5:\n",
    "        return 1\n",
    "    elif TR_avg<0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return random.sample(range(2),1)[0]\n",
    "def choice_rate(participant_code,subsession_round_number,column,df):\n",
    "    return df[(df['participant_code']==participant_code)&(df['subsession_round_number']>subsession_round_number)][column].mean()\n",
    "def to_bin(CR):\n",
    "    if CR<0.25:\n",
    "        return 1\n",
    "    elif CR<0.5:\n",
    "        return 2\n",
    "    elif CR<0.75:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4 \n",
    "def is_same(true,pred):\n",
    "    if true==pred:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def is_same_and_label(same,label):\n",
    "    return same*label\n",
    "def per_trial(participant_code,subsession_round_number,column,df):\n",
    "    return df[(df['participant_code']==participant_code)&(df['subsession_round_number']>subsession_round_number)][column].sum()\n",
    "def labels(metric,label,df):\n",
    "    df[metric[:len(metric)-8]+'_is_'+str(label)]=df.apply(lambda x:is_same(x[metric[:len(metric)-8]],label),axis=1)\n",
    "    df[metric+'_is_'+str(label)]=df.apply(lambda x:is_same(x[metric],label),axis=1)\n",
    "    df[metric+'_is_same_and_'+str(label)]=df.apply(lambda x:is_same_and_label(x[metric+'_is_same'],x[metric+'_is_'+str(label)]),axis=1)\n",
    "    return df\n",
    "df['TR']=df['player_answer']\n",
    "df['TR_average']=df.apply(lambda x: TR_average(x['participant_code'],x['hotel_id'],df),axis=1)\n",
    "df['TR_majorty']=df.apply(lambda x: TR_majorty(x['TR_average']),axis=1)\n",
    "df['CR']=df.apply(lambda x: choice_rate(x['participant_code'],x['subsession_round_number'],'TR',df),axis=1)\n",
    "df['CR_average']=df.apply(lambda x: choice_rate(x['participant_code'],x['subsession_round_number'],'TR_average',df),axis=1)\n",
    "df['CR_majorty']=df.apply(lambda x: choice_rate(x['participant_code'],x['subsession_round_number'],'TR_majorty',df),axis=1)\n",
    "df['CR_bin']=df.apply(lambda x: to_bin(x['CR']),axis=1)\n",
    "df['CR_bin_average']=df.apply(lambda x: to_bin(x['CR_average']),axis=1)\n",
    "df['CR_bin_majorty']=df.apply(lambda x: to_bin(x['CR_majorty']),axis=1)\n",
    "TR_F1=0\n",
    "TR_bins_F1=[]\n",
    "df['TR_majorty_is_same']=df.apply(lambda x:is_same(x['TR'],x['TR_majorty']),axis=1)\n",
    "df['TR_majorty_is_same_per_trial']=df.apply(lambda x:per_trial(x['participant_code'],x['subsession_round_number'],'TR_majorty_is_same',df),axis=1)\n",
    "no_last_trial=df[df['subsession_round_number']<10]\n",
    "TR_accuracy=no_last_trial['TR_majorty_is_same_per_trial'].sum()/(10-no_last_trial['subsession_round_number']).sum()\n",
    "for label in range(2):\n",
    "    df=labels('TR_majorty',label,df)\n",
    "    df['TR_is_'+str(label)+'_per_trial']=df.apply(lambda x:per_trial(x['participant_code'],x['subsession_round_number'],'TR_is_'+str(label),df),axis=1)\n",
    "    df['TR_majorty_is_'+str(label)+'_per_trial']=df.apply(lambda x:per_trial(x['participant_code'],x['subsession_round_number'],'TR_majorty_is_'+str(label),df),axis=1)\n",
    "    df['TR_majorty_is_same_and_'+str(label)+'_per_trial']=df.apply(lambda x:per_trial(x['participant_code'],x['subsession_round_number'],'TR_majorty_is_same_and_'+str(label),df),axis=1)\n",
    "    no_last_trial=df[df['subsession_round_number']<10]\n",
    "    recall=no_last_trial['TR_majorty_is_same_and_'+str(label)+'_per_trial'].sum()/no_last_trial['TR'+'_is_'+str(label)+'_per_trial'].sum()\n",
    "    precision=no_last_trial['TR_majorty_is_same_and_'+str(label)+'_per_trial'].sum()/no_last_trial['TR_majorty_is_'+str(label)+'_per_trial'].sum()\n",
    "    F1=2*recall*precision/(recall+precision)\n",
    "    TR_bins_F1.append(F1)\n",
    "    TR_F1+=F1/2\n",
    "print(\"TR_accuracy:\",TR_accuracy,\"TR_F1\",TR_F1)\n",
    "print(\"TR_bins_F1, hotel=0,hotel=1:\",TR_bins_F1)\n",
    "CR_RMSE=[]\n",
    "CR_F1=[0,0]\n",
    "CR_bins_F1=[[],[]]\n",
    "metrics=['CR_bin_average','CR_bin_majorty']\n",
    "for i in range(2):\n",
    "    no_last_trial=df[df['subsession_round_number']<10]\n",
    "    CR_RMSE.append(mean_squared_error(no_last_trial['CR_'+metrics[i][7:]],no_last_trial['CR'],squared=False))\n",
    "    df[metrics[i]+'_is_same']=df.apply(lambda x:is_same(x['CR_bin'],x[metrics[i]]),axis=1)\n",
    "    for label in range(1,5):\n",
    "        df=labels(metrics[i],label,df)\n",
    "        no_last_trial=df[df['subsession_round_number']<10]\n",
    "        recall=no_last_trial[metrics[i]+'_is_same_and_'+str(label)].sum()/no_last_trial['CR_bin_is_'+str(label)].sum()\n",
    "        precision=no_last_trial[metrics[i]+'_is_same_and_'+str(label)].sum()/no_last_trial[metrics[i]+'_is_'+str(label)].sum()\n",
    "        F1=2*recall*precision/(recall+precision)\n",
    "        CR_bins_F1[i].append(F1)\n",
    "        CR_F1[i]+=F1/4\n",
    "print(\"CR_MSE, avg vs majority:\",CR_RMSE,\"CR_F1, avg vs majority:\",CR_F1)\n",
    "print('CR_bins_F1, avg vs majority: CR<0.25, 0.25<CR<0.5, 0.5<CR<0.75, 0.75<CR',CR_bins_F1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
